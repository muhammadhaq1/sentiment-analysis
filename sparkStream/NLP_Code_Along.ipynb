{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark as ps\n",
    "import warnings\n",
    "# sc = ps.SparkContext()\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just created a SparkContext\n"
     ]
    }
   ],
   "source": [
    "# spark = SparkSession.builder.appName('nlp').getOrCreate()\n",
    "\n",
    "try:\n",
    "    # create SparkContext on all CPUs available: in my case I have 4 CPUs on my laptop\n",
    "    sc = ps.SparkContext('local[4]')\n",
    "    sqlContext = SQLContext(sc)\n",
    "    print(\"Just created a SparkContext\")\n",
    "except ValueError:\n",
    "    warnings.warn(\"SparkContext already exists in this scope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[4]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('clean_tweet.csv')\n",
    "# data = spark.read.csv(\"./dataFinal.csv\",inferSchema=True,sep=',',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.withColumnRenamed('_c0','sentiment').withColumnRenamed('_c1','text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+\n",
      "|_c0|                text|target|\n",
      "+---+--------------------+------+\n",
      "|  0|awww that s a bum...|     0|\n",
      "|  1|is upset that he ...|     0|\n",
      "|  2|i dived many time...|     0|\n",
      "|  3|my whole body fee...|     0|\n",
      "|  4|no it s not behav...|     0|\n",
      "+---+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596747"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, val_set, test_set) = df.randomSplit([0.50, 0.25, 0.25], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|_c0|                text|target|               words|            filtered|                  cv|            features|label|\n",
      "+---+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|  0|awww that s a bum...|     0|[awww, that, s, a...|[awww, that, s, a...|(179480,[1,2,4,6,...|(179480,[1,2,4,6,...|  0.0|\n",
      "|  1|is upset that he ...|     0|[is, upset, that,...|[is, upset, that,...|(179480,[2,4,5,7,...|(179480,[2,4,5,7,...|  0.0|\n",
      "|  2|i dived many time...|     0|[i, dived, many, ...|[i, dived, many, ...|(179480,[0,1,9,11...|(179480,[0,1,9,11...|  0.0|\n",
      "|  4|no it s not behav...|     0|[no, it, s, not, ...|[no, it, s, not, ...|(179480,[0,4,6,10...|(179480,[0,4,6,10...|  0.0|\n",
      "|  7|hey long time no ...|     0|[hey, long, time,...|[hey, long, time,...|(179480,[0,2,6,10...|(179480,[0,2,6,10...|  0.0|\n",
      "+---+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer,HashingTF\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\",\"@\"]\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
    "# hashtf = HashingTF(numFeatures=2**16, inputCol=\"filtered\", outputCol='tf')\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\" , minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[tokenizer,stopwordsRemover,cv, idf, label_stringIdx])\n",
    "\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "val_df = pipelineFit.transform(val_set)\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression,NaiveBayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(maxIter=100)\n",
    "nb = NaiveBayes(modelType=\"multinomial\")\n",
    "nbModel = nb.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbPredictions = nbModel.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "nbEval = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "nbAcc = nbEval.evaluate(nbPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[155196.,  44525.],\n",
      "             [ 48202., 151398.]])\n",
      "Acc of NB:  0.5356720499219636\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "predictionAndLabel = nbPredictions.select(\"prediction\", \"label\").rdd\n",
    "\n",
    "# Generate confusion matrix\n",
    "metrics = MulticlassMetrics(predictionAndLabel)\n",
    "print( metrics.confusionMatrix())\n",
    "print(\"Acc of NB: \",nbAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lrModel = lr.fit(train_df)\n",
    "predictions = lrModel.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8586692560746748"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7953\n",
      "ROC-AUC: 0.8645\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
    "cv = CountVectorizer(vocabSize=2**16, inputCol=\"filtered\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwordsRemover,cv, idf, label_stringIdx, lr])\n",
    "\n",
    "pipelineFit1 = pipeline.fit(train_set)\n",
    "predictions = pipelineFit.transform(val_set)\n",
    "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy))\n",
    "print(\"ROC-AUC: {0:.4f}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.util import MLWritable, MLReadable\n",
    "# MLWritable.save(lrModel,'rash')\n",
    "# lrModel.save('rashid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit1.write().overwrite().save(\"tmp/rasNas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.repartition(200).write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"tmp/testdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedLR = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "abc = PipelineModel.load(\"tmp/rasNas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testResult = abc.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "| _c0|                text|target|               words|            filtered|                  cv|            features|label|       rawPrediction|         probability|prediction|\n",
      "+----+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "| 211|but this is canad...|     0|[but, this, is, c...|[but, this, is, c...|(65536,[1,7,18,25...|(65536,[1,7,18,25...|  0.0|[3.03563028398918...|[0.95415807476462...|       0.0|\n",
      "| 470|cant see the flow...|     0|[cant, see, the, ...|[cant, see, flowe...|(65536,[0,2,3,16,...|(65536,[0,2,3,16,...|  0.0|[1.77173027835149...|[0.85467271611953...|       0.0|\n",
      "| 484|have watched that...|     0|[have, watched, t...|[have, watched, t...|(65536,[0,3,13,16...|(65536,[0,3,13,16...|  0.0|[0.44059729280955...|[0.60840134446001...|       0.0|\n",
      "| 540|i know exactly ho...|     0|[i, know, exactly...|[i, know, exactly...|(65536,[0,6,56,66...|(65536,[0,6,56,66...|  0.0|[-0.5999989869018...|[0.35434392555513...|       1.0|\n",
      "| 748|still procrastina...|     0|[still, procrasti...|[still, procrasti...|(65536,[0,3,10,15...|(65536,[0,3,10,15...|  0.0|[1.15877893097578...|[0.76111076944043...|       0.0|\n",
      "| 960|im boredd gah i w...|     0|[im, boredd, gah,...|[im, boredd, gah,...|(65536,[0,4,5,18,...|(65536,[0,4,5,18,...|  0.0|[3.70958206311851...|[0.97609756159727...|       0.0|\n",
      "|1173|time to get dress...|     0|[time, to, get, d...|[time, to, get, d...|(65536,[0,1,33,49...|(65536,[0,1,33,49...|  0.0|[0.83482941955730...|[0.69737511578875...|       0.0|\n",
      "|1187|it just makes me ...|     0|[it, just, makes,...|[it, just, makes,...|(65536,[0,1,4,5,1...|(65536,[0,1,4,5,1...|  0.0|[2.17645240960213...|[0.89811490972088...|       0.0|\n",
      "|1229|discoteca i just ...|     0|[discoteca, i, ju...|[discoteca, i, ju...|(65536,[0,19,25,5...|(65536,[0,19,25,5...|  0.0|[1.42155312682440...|[0.80558178223549...|       0.0|\n",
      "|1259|your phone doesn ...|     0|[your, phone, doe...|[your, phone, doe...|(65536,[4,34,41,1...|(65536,[4,34,41,1...|  0.0|[2.11784038126285...|[0.89262511517742...|       0.0|\n",
      "|1514|i was just thinki...|     0|[i, was, just, th...|[i, was, just, th...|(65536,[0,4,7,13,...|(65536,[0,4,7,13,...|  0.0|[-1.7428554532730...|[0.14895060198014...|       1.0|\n",
      "|1570|lonely bed no hus...|     0|[lonely, bed, no,...|[lonely, bed, no,...|(65536,[36,135,91...|(65536,[36,135,91...|  0.0|[2.50542254882093...|[0.92452108758607...|       0.0|\n",
      "|1607|terrified by the ...|     0|[terrified, by, t...|[terrified, by, n...|(65536,[53,120,44...|(65536,[53,120,44...|  0.0|[0.91738845731181...|[0.71450968717830...|       0.0|\n",
      "|1621|i just let my eve...|     0|[i, just, let, my...|[i, just, let, my...|(65536,[0,3,4,16,...|(65536,[0,3,4,16,...|  0.0|[3.17071948104707...|[0.95971740884740...|       0.0|\n",
      "|1721|only one to fill ...|     0|[only, one, to, f...|[only, one, to, f...|(65536,[0,1,6,13,...|(65536,[0,1,6,13,...|  0.0|[2.85455114354374...|[0.94555346094494...|       0.0|\n",
      "|1793|whoh what a day n...|     0|[whoh, what, a, d...|[whoh, what, a, d...|(65536,[2,9,26,30...|(65536,[2,9,26,30...|  0.0|[-0.2900518882927...|[0.42799116400276...|       1.0|\n",
      "|2184|    why not saturday|     0|[why, not, saturday]|[why, not, saturday]|(65536,[23,107,41...|(65536,[23,107,41...|  0.0|[1.78384417019342...|[0.85617089429300...|       0.0|\n",
      "|2465|i m not happy i w...|     0|[i, m, not, happy...|[i, m, not, happy...|(65536,[0,1,5,17,...|(65536,[0,1,5,17,...|  0.0|[1.53567744024960...|[0.82283547340210...|       0.0|\n",
      "|2563|wishing you the best|     0|[wishing, you, th...|[wishing, you, best]|(65536,[6,169,702...|(65536,[6,169,702...|  0.0|[0.02271634512430...|[0.50567884207766...|       0.0|\n",
      "|2573|know of any more ...|     0|[know, of, any, m...|[know, of, any, m...|(65536,[0,1,11,12...|(65536,[0,1,11,12...|  0.0|[-0.2028498662351...|[0.44946071420688...|       1.0|\n",
      "+----+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testResult.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
