{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from joblib import dump, load\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-9dd8a9e5808f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-9dd8a9e5808f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    function happy_number(num)\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "function happy_number(num) \n",
    "{\n",
    "    var m, n ;\n",
    "    var c = [] ;\n",
    " \n",
    "    while(num != 1 && c[num] !== true) \n",
    "    {\n",
    "        c[num] = true ;\n",
    "        m = 0 ;\n",
    "        while (num > 0) {\n",
    "            n = num % 10 ;\n",
    "            m += n * n ;\n",
    "            num = (num  - n) / 10 ;\n",
    "        }\n",
    "        num = m ;\n",
    "    }\n",
    "    return (num == 1) ;\n",
    "}\n",
    " \n",
    "var cnt = 5;\n",
    "var num = 1;\n",
    "var f5 = ''; \n",
    "while(cnt-- > 0) \n",
    "{\n",
    "    while(!happy_number(num))\n",
    "        num++ ;\n",
    "f5 = f5+(num + \", \") ;\n",
    "    \n",
    "num++ ;\n",
    "}\n",
    "console.log('First 5 happy numbers are : '+f5);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_matched(expression):\n",
    "    \"\"\"\n",
    "    Finds out how balanced an expression is.\n",
    "    With a string containing only brackets.\n",
    "\n",
    "    >>> is_matched('[]()()(((([])))')\n",
    "    False\n",
    "    >>> is_matched('[](){{{[]}}}')\n",
    "    True\n",
    "    \"\"\"\n",
    "    opening = tuple('({[')\n",
    "    closing = tuple(')}]')\n",
    "    mapping = dict(zip(opening, closing))\n",
    "    queue = []\n",
    "\n",
    "    for letter in expression:\n",
    "        if letter in opening:\n",
    "            queue.append(mapping[letter])\n",
    "        elif letter in closing:\n",
    "            if not queue or letter != queue.pop():\n",
    "                return False\n",
    "    return not queue\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     import doctest\n",
    "    \n",
    "#     doctest.testmod()\n",
    "is_matched(\"([])\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer,HashingTF\n",
    "CountVectorizer\n",
    "HashingTF\n",
    "IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./clean_tweet.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1200205</th>\n",
       "      <td>i m honored my friend have a great week</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097971</th>\n",
       "      <td>hahas gotta change airline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306692</th>\n",
       "      <td>grrrrrrrr my picture isn t showing up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94044</th>\n",
       "      <td>el pollo loco commercials gross me out i can j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211014</th>\n",
       "      <td>see wouldnt it have been easier if you were on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  target\n",
       "1200205            i m honored my friend have a great week       1\n",
       "1097971                         hahas gotta change airline       1\n",
       "306692               grrrrrrrr my picture isn t showing up       0\n",
       "94044    el pollo loco commercials gross me out i can j...       0\n",
       "1211014  see wouldnt it have been easier if you were on...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.target = data.target.replace(4,1)\n",
    "data = shuffle(data, random_state=22)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_data_size = int(len(data) * .9)\n",
    "# print(used_data_size)\n",
    "used_data = data[:used_data_size]\n",
    "# print(len(used_data))\n",
    "type(used_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_split = [str(tags) for tags in used_data['target'].values]\n",
    "# print(tags_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i m honored my friend have a great week\n",
      "['0' '1']\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "tag_encoder = MultiLabelBinarizer()\n",
    "tags_encoded = tag_encoder.fit_transform(tags_split)\n",
    "# print(tags_encoded)\n",
    "num_tags = len(tags_encoded[0])\n",
    "# print(num_tags)\n",
    "print(data['text'].values[0])\n",
    "print(tag_encoder.classes_)\n",
    "print(tags_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1149657\n",
      "Test size: 287415\n"
     ]
    }
   ],
   "source": [
    "# Spliting  data into train and test sets\n",
    "train_size = int(len(used_data) * .8)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(used_data) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags = tags_encoded[:train_size]\n",
    "test_tags = tags_encoded[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess1.py\n",
    "\n",
    "# Pre-processing data: create our tokenizer class\n",
    "\n",
    "from tensorflow.keras.preprocessing import text\n",
    "\n",
    "class TextPreprocessor(object):\n",
    "  def __init__(self, vocab_size):\n",
    "    self._vocab_size = vocab_size\n",
    "    self._tokenizer = None\n",
    "  \n",
    "  def create_tokenizer(self, text_list):\n",
    "    tokenizer = text.Tokenizer(num_words=self._vocab_size)\n",
    "    tokenizer.fit_on_texts(text_list)\n",
    "    self._tokenizer = tokenizer\n",
    "\n",
    "  def transform_text(self, text_list):\n",
    "    text_matrix = self._tokenizer.texts_to_matrix(text_list)\n",
    "    return text_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab from training corpus\n",
    "from preprocess import TextPreprocessor\n",
    "\n",
    "VOCAB_SIZE=400 # This is a hyperparameter, try out different values for your dataset\n",
    "\n",
    "train_qs = used_data['text'].values[:train_size]\n",
    "test_qs = used_data['text'].values[train_size:]\n",
    "\n",
    "processor = TextPreprocessor(VOCAB_SIZE)\n",
    "processor.create_tokenizer(train_qs)\n",
    "\n",
    "body_train = processor.transform_text(train_qs)\n",
    "body_test = processor.transform_text(test_qs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first input from our training data\n",
    "print(len(body_train[0]))\n",
    "print(body_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./processor_state1.pkl', 'wb') as f:\n",
    "  pickle.dump(processor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  \n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Dense(50, input_shape=(400,), activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
    "#   model.add(tf.keras.layers.Dense(20, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 50)                20050     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 21,377\n",
      "Trainable params: 21,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1034691 samples, validate on 114966 samples\n",
      "Epoch 1/8\n",
      "1034691/1034691 [==============================] - 254s 245us/step - loss: 0.5073 - acc: 0.7466 - val_loss: 0.4949 - val_acc: 0.7547\n",
      "Epoch 2/8\n",
      "1034691/1034691 [==============================] - 239s 231us/step - loss: 0.4901 - acc: 0.7580 - val_loss: 0.4912 - val_acc: 0.7567\n",
      "Epoch 3/8\n",
      "1034691/1034691 [==============================] - 202s 195us/step - loss: 0.4845 - acc: 0.7614 - val_loss: 0.4895 - val_acc: 0.7590\n",
      "Epoch 4/8\n",
      "1034691/1034691 [==============================] - 156s 151us/step - loss: 0.4808 - acc: 0.7637 - val_loss: 0.4888 - val_acc: 0.7585\n",
      "Epoch 5/8\n",
      "1034691/1034691 [==============================] - 130s 126us/step - loss: 0.4782 - acc: 0.7652 - val_loss: 0.4886 - val_acc: 0.7585\n",
      "Epoch 6/8\n",
      "1034691/1034691 [==============================] - 131s 126us/step - loss: 0.4764 - acc: 0.7665 - val_loss: 0.4882 - val_acc: 0.7590\n",
      "Epoch 7/8\n",
      "1034691/1034691 [==============================] - 103s 99us/step - loss: 0.4750 - acc: 0.7675 - val_loss: 0.4881 - val_acc: 0.7592\n",
      "Epoch 8/8\n",
      "1034691/1034691 [==============================] - 81s 79us/step - loss: 0.4738 - acc: 0.7681 - val_loss: 0.4876 - val_acc: 0.7601\n",
      "287415/287415 [==============================] - 7s 24us/step\n",
      "Eval loss/accuracy:[0.49138158754157435, 0.7569994607142706]\n"
     ]
    }
   ],
   "source": [
    "# model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "model = create_model()\n",
    "model.summary()\n",
    "# batch_size = [40, 60]\n",
    "# epochs = [3, 6, 8]\n",
    "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "# grid_result = grid.fit(body_train, train_tags)\n",
    "# Train and evaluate the model\n",
    "model.fit(body_train, train_tags, epochs=8, batch_size=64, validation_split=0.1)\n",
    "print('Eval loss/accuracy:{}'.format(\n",
    "  model.evaluate(body_test, test_tags, batch_size=64)))\n",
    "\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# Export the model to a file\n",
    "# model.save('keras_saved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=8, batch_size=60, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(body_train, train_tags)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
